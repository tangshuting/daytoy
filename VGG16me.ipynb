{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16me.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLu8EMxNDF4NkDWbZXT+Ub",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tangshuting/daytoy/blob/master/VGG16me.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VXfbVCdGgNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16网络的搭建\n",
        "# import keras\n",
        "# from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D  # 二维卷积层，即对图像的空域卷积。\n",
        "from keras.layers.convolutional import MaxPooling2D  # 空间池化（也叫亚采样或下采样）降低了每个特征映射的维度，但是保留了最重要的信息\n",
        "from keras.layers import Flatten, Dense # Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib as mpl \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnDx7hLaGkJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() #第一个元组储存训练好的图片和对应标签,第二个元组是未分类图片\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)    #样本规模，像素通道，长度，宽度 四维\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# 给定的像素的灰度值在0-255，为了使模型的训练效果更好，通常将数值归一化映射到0-1\n",
        "# astype函数修改数据类型为浮点型\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "# one hot encoding，convert class vectors to binary class matrices\n",
        "num_classes=10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o5YnaZDAc5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# def create_VGG16():\n",
        "VGG16= Sequential()\n",
        "VGG16.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "    \n",
        "VGG16.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "    \n",
        "VGG16.add(MaxPooling2D(2, 2))\n",
        "\n",
        "VGG16.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(MaxPooling2D(2, 2))\n",
        "\n",
        "VGG16.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(MaxPooling2D(2, 2))\n",
        "\n",
        "VGG16.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(MaxPooling2D(2, 2))\n",
        "\n",
        "VGG16.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "VGG16.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "VGG16.add(Flatten())\n",
        "\n",
        "VGG16.add(Dense(1024, activation='relu'))\n",
        "VGG16.add(Dense(1024, activation='relu'))\n",
        "VGG16.add(Dense(10, activation='softmax')) #最后一层是输出层，有10个神经元，每个神经元对应一个类别，输出值表示样本属于该类别的概率大小。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9qdy5IUGb_g",
        "colab_type": "code",
        "outputId": "8c33aac6-8dbf-4b3a-e735-bc39747eccd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "# 模型概括打印\n",
        "VGG16.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 14, 14, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 3, 3, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 3, 3, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 1, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 1, 1, 256)         590080    \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 1, 1, 256)         590080    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              263168    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 3,276,090\n",
            "Trainable params: 3,276,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqVExHjmGRwa",
        "colab_type": "code",
        "outputId": "4ed8d5ab-1a26-4f06-f6d2-1af2623f6cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "VGG16.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "# return VGG16\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "# VGG16.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, verbose=2, validation_data=(x_test, y_test))\n",
        "VGG16.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 420s - loss: 1.0512 - acc: 0.6158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f411b12bd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulzztNyYGZNl",
        "colab_type": "code",
        "outputId": "42a9c2c4-3508-4813-bb97-0d34a74e90fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#评估模型\n",
        "score = VGG16.evaluate(x_test, y_test)\n",
        "print('loss： %.4lf' % score[0])\n",
        "print('accuracy: ', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 1ms/step\n",
            "loss： 0.2161\n",
            "accuracy:  0.9397000074386597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkiN1URfEO7j",
        "colab_type": "code",
        "outputId": "422e263c-78c1-4610-a8eb-566b3da3056a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "image = x_test[234]\n",
        "y_true = y_test[234]\n",
        "print ('y_true:',y_true)\n",
        "plt.figure()\n",
        "plt.imshow(image)\n",
        "image = image.reshape(-1,28,28,1).astype('float32')\n",
        "iamge = image/255\n",
        "y_true = np_utils.to_categorical(1,10)  #one-hot编码\n",
        "print ('y_true:',y_true)\n",
        "print ('iamge:',image.shape)\n",
        "print ('y_true:',y_true.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_true: 7\n",
            "y_true: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "iamge: (1, 28, 28, 1)\n",
            "y_true: (10,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1grG8CAVJeFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend, losses\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udr_KxPcFolB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fgsm( VGG16, image, y_true, eps=0.1):\n",
        "   \n",
        "    #image_pred = m_model.predict_classes(img)\n",
        "    predict = VGG16.predict(image)\n",
        "    image_pred = np.argmax(predict,axis=1)\n",
        "    image_pred = np_utils.to_categorical(image_pred, 10)\n",
        "\n",
        "    loss = losses.categorical_crossentropy(y_true, image_pred)\n",
        "    gradient = backend.gradients(loss, y_true)   \n",
        "    gradient = gradient[0]\n",
        "\n",
        "    adv = image + backend.sign(gradient) * eps  # fgsm算法\n",
        "\n",
        "    # sess = backend.get_session()   #设置会话\n",
        "    # adv = sess.run(adv, feed_dict={model.input: image})  # 注意这里传递参数的情况\n",
        "    adv = np.clip(adv, 0, 1)  \n",
        "    return adv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGmTciHRFtjS",
        "colab_type": "code",
        "outputId": "ce1b75b2-50a4-4402-c452-c61df4155cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "def fgsm_attack(image):\n",
        "   \n",
        "    epsilons = [0, 0.01, 0.1, 0.15, 0.2]\n",
        "\n",
        "    print(\"开始使用fgsm进行攻击\")\n",
        "    for i, eps in enumerate(epsilons):\n",
        "        img_attack = fgsm(VGG16, image, y_true, eps=eps)\n",
        "        plt.figure()\n",
        "        plt.imshow(img_attack)\n",
        "        #attack =keras.m_model.predict_classes(img_attack)\n",
        "        attack = VGG16.predict(img_attack)\n",
        "        fgsm_attack = np.argmax(attackt,axis=1)\n",
        "        Y_adv = np_utils.to_categorical(fgsm_attack, 10)\n",
        "\n",
        "        # 当识别的结果不等时，表示攻击成功\n",
        "        #if attack != y_pred:\n",
        "        if Y_adv != image_pred:\n",
        "            print('攻击成功，攻击后的结果为：', Y_adv)\n",
        "fgsm_attack(image)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "开始使用fgsm进行攻击\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-794fe9f04fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY_adv\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mimage_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'攻击成功，攻击后的结果为：'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mfgsm_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-794fe9f04fa4>\u001b[0m in \u001b[0;36mfgsm_attack\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"开始使用fgsm进行攻击\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimg_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_attack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-84544017a204>\u001b[0m in \u001b[0;36mfgsm\u001b[0;34m(VGG16, image, y_true, eps)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimage_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing)\u001b[0m\n\u001b[1;32m   1525\u001b[0m   y_true = smart_cond.smart_cond(label_smoothing,\n\u001b[1;32m   1526\u001b[0m                                  _smooth_labels, lambda: y_true)\n\u001b[0;32m-> 1527\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4560\u001b[0m   \"\"\"\n\u001b[0;32m-> 4561\u001b[0;31m   \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4562\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4563\u001b[0m     return nn.softmax_cross_entropy_with_logits_v2(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \"\"\"\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes (10,) and (1, 10) are incompatible"
          ]
        }
      ]
    }
  ]
}