{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VT_CNN2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQDBEj9Dk1ge5hr36wptxp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tangshuting/daytoy/blob/master/VT_CNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJKS2HKANAX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5ab9acd-b15f-42fe-93a1-ac728fcee0c6"
      },
      "source": [
        "import keras.models as models\n",
        "# from keras.models as models\n",
        "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.convolutional import Convolution2D,MaxPooling2D,ZeroPadding2D\n",
        "from keras.optimizers import adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84o3bwqceCC_",
        "colab_type": "code",
        "outputId": "d8e0c804-5110-40f5-9839-6023cc48983b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "from scipy import integrate\n",
        "import os,random\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "#os.environ[\"THEANO_FLAGS\"]  = \"device=cuda,floatX=float32\"\n",
        "from keras.utils import np_utils\n",
        "import keras.models as models\n",
        "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.noise import GaussianNoise\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.regularizers import *\n",
        "from keras.optimizers import adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle, random, sys, keras\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f = open(r'/content/drive/My Drive/EMW/2016.04C.multisnr.pkl','rb') \n",
        "dataDict = pickle.load(f,encoding='bytes')\n",
        "print(type(dataDict))   # dict\n",
        "print(len(dataDict))  #220=11（类别）×20（20个snr）\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "for d in dataDict:\n",
        "   signals=dataDict[d]\n",
        "   for s in signals:\n",
        "     data.append(np.array(s))\n",
        "     labels.append(d)\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "<class 'dict'>\n",
            "220\n",
            "(162060, 2, 128)\n",
            "(162060, 2)\n",
            "[[b'QPSK' b'2']\n",
            " [b'QPSK' b'2']\n",
            " [b'QPSK' b'2']\n",
            " ...\n",
            " [b'WBFM' b'12']\n",
            " [b'WBFM' b'12']\n",
            " [b'WBFM' b'12']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXIoBnctem7K",
        "colab_type": "code",
        "outputId": "6d9d1286-c16b-4810-ec85-5c6c608dd6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# 划分数据集 手动（固定的）和自动（可随机选）\n",
        "\n",
        "# 使用函数分测试集和训练集\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# xTrain, xTest, yTrain, yTest = train_test_split(data,labels, test_size=0.5, random_state=62)\n",
        "\n",
        "indices = random.sample(range(0,162060),162060)\n",
        "xTrain = []\n",
        "yTrain = []\n",
        "iTrain = []\n",
        "for i in range(0,81030):\n",
        "  xTrain.append(data[indices[i]])\n",
        "  yTrain.append(labels[indices[i]])\n",
        "  iTrain.append(indices[i])\n",
        "xTrain = np.array(xTrain)\n",
        "yTrain = np.array(yTrain)\n",
        "iTrain = np.array(iTrain)\n",
        "\n",
        "xTest = []\n",
        "yTest = []\n",
        "iTest = []\n",
        "for i in range(81030, 162060):\n",
        "  xTest.append(data[indices[i]])\n",
        "  yTest.append(labels[indices[i]])\n",
        "  iTest.append(indices[i])\n",
        "xTest = np.array(xTrain)\n",
        "yTest = np.array(yTrain)\n",
        "iTest = np.array(iTest)\n",
        "\n",
        "print(xTrain.shape)\n",
        "print(yTrain.shape)\n",
        "print(xTest.shape)\n",
        "print(yTest.shape)\n",
        "print(iTrain.shape)\n",
        "print(iTest.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(81030, 2, 128)\n",
            "(81030, 2)\n",
            "(81030, 2, 128)\n",
            "(81030, 2)\n",
            "(81030,)\n",
            "(81030,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks7iM-xVejb-",
        "colab_type": "code",
        "outputId": "bb09de97-644c-49c6-dd15-7393c962fd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "\n",
        "# one-hot enconding\n",
        "#Sklearn’s one hot encoder doesn’t actually know how to convert categories to numbers,\n",
        "#it only knows how to convert numbers to binary. We have to use the labelencoder first.\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "yTrain_SNR = yTrain[:,1]\n",
        "yTest_SNR = yTest[:,1]\n",
        "print(yTrain_SNR.shape)\n",
        "print(yTest_SNR.shape)\n",
        "print(yTrain_SNR)\n",
        "print(yTest_SNR)\n",
        "print(yTest[81028])  #随便找一个例子看一下输出结果是否正确\n",
        "print(yTest_SNR[81028])\n",
        "\n",
        "yTrain_le = le.fit_transform(yTrain[:, 0])\n",
        "yTest_le = le.fit_transform(yTest[:, 0])\n",
        "print(yTrain_le.shape)\n",
        "print(yTest_le.shape)\n",
        "print(yTrain_le[81028])\n",
        "print(yTest_le[81028])   #label编码后\n",
        "\n",
        "yTrain_le = yTrain_le.reshape(len(yTrain_le), 1)\n",
        "yTest_le = yTest_le.reshape(len(yTest_le), 1)\n",
        "\n",
        "enc = OneHotEncoder(categories = 'auto',sparse = False )  #将分类特征的每个元素转化为一个可以用来计算的值\n",
        "yTrain_ohe = enc.fit_transform(yTrain_le)  # 如果不加 toarray() 的话，输出的是稀疏的存储格式，即索引加值的形式，也可以通过参数指定 sparse = False 来达到同样的效果\n",
        "yTest_ohe = enc.fit_transform(yTest_le)\n",
        "print(yTrain_ohe[81028])  #onehot编码后\n",
        "print(yTest_ohe[81028])  #onehot编码后\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(81030,)\n",
            "(81030,)\n",
            "[b'-14' b'-14' b'-18' ... b'2' b'6' b'4']\n",
            "[b'-14' b'-14' b'-18' ... b'2' b'6' b'4']\n",
            "[b'GFSK' b'6']\n",
            "b'6'\n",
            "(81030,)\n",
            "(81030,)\n",
            "5\n",
            "5\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRP58XnKolwI",
        "colab_type": "code",
        "outputId": "98c63bd9-3a2d-45a4-bcfc-105646ff4d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "import os,random\n",
        "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "os.environ[\"THEANO_FLAGS\"]  = \"device=gpu%d\"%(1)\n",
        "import numpy as np\n",
        "import theano as th\n",
        "import theano.tensor as T\n",
        "from keras.utils import np_utils\n",
        "import keras.models as models\n",
        "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.noise import GaussianNoise\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.regularizers import *\n",
        "from keras.optimizers import adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "dr = 0.5 # dropout rate (%)\n",
        "model = models.Sequential()\n",
        "in_shp = [2, 128]\n",
        "model.add(Reshape([1]+in_shp, input_shape=in_shp))\n",
        "model.add(ZeroPadding2D((0, 2)))\n",
        "model.add(Convolution2D(256, 1, 3, border_mode='valid', activation=\"relu\", name=\"conv1\", init='glorot_uniform'))\n",
        "model.add(Dropout(dr))\n",
        "model.add(ZeroPadding2D((0, 2)))\n",
        "model.add(Convolution2D(80, 1, 3, border_mode=\"valid\", activation=\"relu\", name=\"conv2\", init='glorot_uniform'))  #(80,2,3)改成了（80，1，3）\n",
        "model.add(Dropout(dr))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', init='he_normal', name=\"dense1\"))\n",
        "model.add(Dropout(dr))\n",
        "model.add(Dense(11, init='he_normal', name=\"dense2\" ))\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Dense(11,activation='softmax'))\n",
        "# model.add(Reshape(11)) \n",
        "# 加上metrics=['acc']这一句\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam') \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_15 (Reshape)         (None, 1, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPaddi (None, 1, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 1, 4, 256)         98560     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPaddi (None, 1, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 1, 6, 80)          61520     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1, 6, 80)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 256)               123136    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 11)                2827      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 11)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 11)                132       \n",
            "=================================================================\n",
            "Total params: 286,175\n",
            "Trainable params: 286,175\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 3), activation=\"relu\", name=\"conv1\", padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(80, (1, 3), activation=\"relu\", name=\"conv2\", padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", name=\"dense1\", kernel_initializer=\"he_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(11, name=\"dense2\", kernel_initializer=\"he_normal\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyb_0XoHQSVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70f2623f-e3cc-4b43-b97b-f73c4b1baa41"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "epochs=50\n",
        "batch_size=1000\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=30)\n",
        "mc = ModelCheckpoint('best.hdf5weights.best2.hdf5', monitor='val_acc', mode='max', save_best_only=True, verbose=1)\n",
        "model.fit(xTrain, yTrain_ohe, validation_split=0.2, shuffle=True, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[es, mc])  #不加 metrics=['accuracy']这一句时，结果显示是loss和val_loss，不显示准去率"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 64824 samples, validate on 16206 samples\n",
            "Epoch 1/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.9827 - accuracy: 0.2829 - val_loss: 1.9583 - val_accuracy: 0.2963\n",
            "Epoch 2/50\n",
            " 1000/64824 [..............................] - ETA: 8s - loss: 1.9401 - accuracy: 0.2940"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.9719 - accuracy: 0.2849 - val_loss: 1.9504 - val_accuracy: 0.3001\n",
            "Epoch 3/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.9688 - accuracy: 0.2831 - val_loss: 1.9459 - val_accuracy: 0.2975\n",
            "Epoch 4/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.9579 - accuracy: 0.2875 - val_loss: 1.9329 - val_accuracy: 0.3004\n",
            "Epoch 5/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.9460 - accuracy: 0.2885 - val_loss: 1.9243 - val_accuracy: 0.3002\n",
            "Epoch 6/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.9378 - accuracy: 0.2907 - val_loss: 1.9241 - val_accuracy: 0.3025\n",
            "Epoch 7/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.9335 - accuracy: 0.2917 - val_loss: 1.9063 - val_accuracy: 0.3054\n",
            "Epoch 8/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.9175 - accuracy: 0.2958 - val_loss: 1.8924 - val_accuracy: 0.3041\n",
            "Epoch 9/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.9123 - accuracy: 0.2946 - val_loss: 1.8874 - val_accuracy: 0.3054\n",
            "Epoch 10/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.9040 - accuracy: 0.2941 - val_loss: 1.8742 - val_accuracy: 0.3047\n",
            "Epoch 11/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8911 - accuracy: 0.2920 - val_loss: 1.8589 - val_accuracy: 0.3046\n",
            "Epoch 12/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8737 - accuracy: 0.2975 - val_loss: 1.8461 - val_accuracy: 0.3037\n",
            "Epoch 13/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8673 - accuracy: 0.2985 - val_loss: 1.8306 - val_accuracy: 0.3022\n",
            "Epoch 14/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.8553 - accuracy: 0.2979 - val_loss: 1.8264 - val_accuracy: 0.3029\n",
            "Epoch 15/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.8541 - accuracy: 0.2975 - val_loss: 1.8356 - val_accuracy: 0.2998\n",
            "Epoch 16/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8414 - accuracy: 0.2958 - val_loss: 1.8087 - val_accuracy: 0.3026\n",
            "Epoch 17/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8320 - accuracy: 0.2954 - val_loss: 1.8045 - val_accuracy: 0.3035\n",
            "Epoch 18/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.8259 - accuracy: 0.2959 - val_loss: 1.7932 - val_accuracy: 0.3050\n",
            "Epoch 19/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8235 - accuracy: 0.2979 - val_loss: 1.7943 - val_accuracy: 0.3030\n",
            "Epoch 20/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.8158 - accuracy: 0.2992 - val_loss: 1.7833 - val_accuracy: 0.3039\n",
            "Epoch 21/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.8135 - accuracy: 0.2963 - val_loss: 1.7922 - val_accuracy: 0.3046\n",
            "Epoch 22/50\n",
            "64824/64824 [==============================] - 9s 139us/step - loss: 1.8098 - accuracy: 0.2978 - val_loss: 1.7780 - val_accuracy: 0.3075\n",
            "Epoch 23/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.8121 - accuracy: 0.3007 - val_loss: 1.7890 - val_accuracy: 0.3035\n",
            "Epoch 24/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8074 - accuracy: 0.2980 - val_loss: 1.7879 - val_accuracy: 0.3051\n",
            "Epoch 25/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.8028 - accuracy: 0.2975 - val_loss: 1.7784 - val_accuracy: 0.3053\n",
            "Epoch 26/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7991 - accuracy: 0.2988 - val_loss: 1.7732 - val_accuracy: 0.3041\n",
            "Epoch 27/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.8059 - accuracy: 0.2959 - val_loss: 1.7719 - val_accuracy: 0.3032\n",
            "Epoch 28/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.7940 - accuracy: 0.2954 - val_loss: 1.7655 - val_accuracy: 0.3054\n",
            "Epoch 29/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7910 - accuracy: 0.2983 - val_loss: 1.7679 - val_accuracy: 0.3037\n",
            "Epoch 30/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7868 - accuracy: 0.3004 - val_loss: 1.7636 - val_accuracy: 0.3045\n",
            "Epoch 31/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7922 - accuracy: 0.3004 - val_loss: 1.7653 - val_accuracy: 0.3024\n",
            "Epoch 32/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7983 - accuracy: 0.3008 - val_loss: 1.7682 - val_accuracy: 0.3055\n",
            "Epoch 33/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.7902 - accuracy: 0.2995 - val_loss: 1.7631 - val_accuracy: 0.3044\n",
            "Epoch 34/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7850 - accuracy: 0.3019 - val_loss: 1.7595 - val_accuracy: 0.3043\n",
            "Epoch 35/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.7866 - accuracy: 0.2996 - val_loss: 1.7625 - val_accuracy: 0.3040\n",
            "Epoch 36/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.7857 - accuracy: 0.2996 - val_loss: 1.7626 - val_accuracy: 0.3031\n",
            "Epoch 37/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7798 - accuracy: 0.3003 - val_loss: 1.7539 - val_accuracy: 0.3057\n",
            "Epoch 38/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7789 - accuracy: 0.3012 - val_loss: 1.7505 - val_accuracy: 0.3069\n",
            "Epoch 39/50\n",
            "64824/64824 [==============================] - 9s 135us/step - loss: 1.7780 - accuracy: 0.3012 - val_loss: 1.7511 - val_accuracy: 0.3074\n",
            "Epoch 40/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.7751 - accuracy: 0.3019 - val_loss: 1.7524 - val_accuracy: 0.3040\n",
            "Epoch 41/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.7764 - accuracy: 0.3010 - val_loss: 1.7456 - val_accuracy: 0.3062\n",
            "Epoch 42/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.7778 - accuracy: 0.3024 - val_loss: 1.7480 - val_accuracy: 0.3077\n",
            "Epoch 43/50\n",
            "64824/64824 [==============================] - 9s 138us/step - loss: 1.7744 - accuracy: 0.3007 - val_loss: 1.7504 - val_accuracy: 0.3045\n",
            "Epoch 44/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.7745 - accuracy: 0.2993 - val_loss: 1.7519 - val_accuracy: 0.3049\n",
            "Epoch 45/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.7775 - accuracy: 0.2987 - val_loss: 1.7498 - val_accuracy: 0.3042\n",
            "Epoch 46/50\n",
            "64824/64824 [==============================] - 9s 136us/step - loss: 1.7726 - accuracy: 0.3019 - val_loss: 1.7478 - val_accuracy: 0.3053\n",
            "Epoch 47/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.7761 - accuracy: 0.2999 - val_loss: 1.7514 - val_accuracy: 0.3017\n",
            "Epoch 48/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.7686 - accuracy: 0.2985 - val_loss: 1.7562 - val_accuracy: 0.2986\n",
            "Epoch 49/50\n",
            "64824/64824 [==============================] - 9s 138us/step - loss: 1.7756 - accuracy: 0.3002 - val_loss: 1.7586 - val_accuracy: 0.3012\n",
            "Epoch 50/50\n",
            "64824/64824 [==============================] - 9s 137us/step - loss: 1.7706 - accuracy: 0.3016 - val_loss: 1.7477 - val_accuracy: 0.3025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fde9c547f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIKS2-91R_VZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "542b7dec-dc98-4c79-8e6b-6d3c7632dd20"
      },
      "source": [
        "batch_size=1000\n",
        "score = model.evaluate(xTest, yTest_ohe, verbose=0, batch_size=batch_size)\n",
        "print (score)   #结果是 1.9665707177208425，不是100%下的结果，这个结果应该是默认的loss\n",
        "print (score[1])  #报错 'float' object is not subscriptable\n",
        "print ('loss： %.4lf' % score[0])\n",
        "print('accuracy: ', score[1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.7418596819125913, 0.30427002906799316]\n",
            "0.30427002906799316\n",
            "loss： 1.7419\n",
            "accuracy:  0.30427002906799316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7FV6B6CegmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "ddcd0e9e-513e-4c44-9860-7c636e835164"
      },
      "source": [
        "\n",
        "\"\"\"###Evaluate Test set\"\"\"\n",
        "\n",
        "\n",
        "filepath = \"VT_CNN2.hdf5\"\n",
        "model.save(filepath)\n",
        "\n",
        "SNR = np.unique(labels[:,1])\n",
        "SNR = list(map(int, SNR))\n",
        "SNR.sort()\n",
        "SNR = list(map(str, SNR))\n",
        "\n",
        "from keras.models import load_model\n",
        "saved_model = load_model('VT_CNN2.hdf5')\n",
        "\n",
        "yTest_SNR_str = []\n",
        "for i in yTest_SNR:\n",
        "  yTest_SNR_str.append(str(i).split('\\'')[1])\n",
        "\n",
        "accuracy = []\n",
        "\n",
        "for s in SNR:\n",
        "    SNR_index = []\n",
        "    SNR_Y = []\n",
        "    SNR_X = []\n",
        "    for index in range(0,len(yTest_SNR_str)):\n",
        "        if s == yTest_SNR_str[index]:\n",
        "            SNR_index.append(index)\n",
        "            SNR_Y.append(yTest_ohe[index])\n",
        "            SNR_X.append(xTest[index])\n",
        "\n",
        "    y = np.array(SNR_Y)\n",
        "    # print(y)\n",
        "    x = np.array(SNR_X)\n",
        "    result = model.evaluate(x, y, verbose=2)\n",
        "    print('Accuracy for SNR = ', s, ' is ', result[1] * 100)\n",
        "    accuracy.append(result[1])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ylim(0, 1)\n",
        "plt.plot(SNR, accuracy)\n",
        "plt.title('VT_CNN2 Classification Accuracy RadioML 2016.04C')\n",
        "plt.xlabel('SNR\\dB')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 曲线不合理：先降后升现象\n",
        "# 解决方法：多画几次\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for SNR =  -20  is  14.65517282485962\n",
            "Accuracy for SNR =  -18  is  15.956120193004608\n",
            "Accuracy for SNR =  -16  is  14.997495710849762\n",
            "Accuracy for SNR =  -14  is  14.909268915653229\n",
            "Accuracy for SNR =  -12  is  15.499146282672882\n",
            "Accuracy for SNR =  -10  is  15.814536809921265\n",
            "Accuracy for SNR =  -8  is  18.428781628608704\n",
            "Accuracy for SNR =  -6  is  24.40711408853531\n",
            "Accuracy for SNR =  -4  is  38.03513944149017\n",
            "Accuracy for SNR =  -2  is  40.476781129837036\n",
            "Accuracy for SNR =  0  is  40.31296670436859\n",
            "Accuracy for SNR =  2  is  38.766297698020935\n",
            "Accuracy for SNR =  4  is  39.26380276679993\n",
            "Accuracy for SNR =  6  is  38.943490386009216\n",
            "Accuracy for SNR =  8  is  39.15175199508667\n",
            "Accuracy for SNR =  10  is  39.57915902137756\n",
            "Accuracy for SNR =  12  is  39.21375870704651\n",
            "Accuracy for SNR =  14  is  39.945852756500244\n",
            "Accuracy for SNR =  16  is  40.004804730415344\n",
            "Accuracy for SNR =  18  is  39.8723304271698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jw1ikrsf1XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
        "import theano as th\n",
        "import theano.tensor as T\n",
        "\n",
        "import keras.models as models\n",
        "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.noise import GaussianNoise\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.regularizers import *\n",
        "from keras.optimizers import adam\n",
        "\n",
        "dr = 0.5 # dropout rate (%)\n",
        "model = models.Sequential()\n",
        "# # model.add(Reshape([1]+in_shp, input_shape=in_shp))\n",
        "# model.add(Reshape((1,2,128), input_shape=(2,128)))\n",
        "# model.add(ZeroPadding2D((0, 2)))\n",
        "# # model.add(Conv2D(filters=256, kernel_size=(1,3), data_format='channels_first', activation='relu', padding='valid'))  #module 'tensorflow._api.v2.config' has no attribute 'experimental_list_devices'\n",
        "# model.add(Conv2D(filters=256, kernel_size=(1,3), data_format='channels_first', activation='relu', padding='valid'))\n",
        "# model.add(Dropout(dr))\n",
        "# model.add(ZeroPadding2D((0, 2)))\n",
        "# model.add(Conv2D(filters=80, kernel_size=(2,3), data_format='channels_first', activation='relu', padding='valid'))\n",
        "# model.add(Dropout(dr))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dropout(dr))\n",
        "# model.add(Dense( 11, activation='softmax' ))\n",
        "# model.add(Reshape(11))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# model.summary()\n",
        "# in_shp=[2,128]\n",
        "# model.add(Reshape([1]+in_shp, input_shape=in_shp))\n",
        "\n",
        "model.add(Reshape((1,2,128), input_shape=(2,128)))\n",
        "model.add(Conv2D(256,(1,3),activation='relu',padding='valid'))\n",
        "model.add(Dropout(dr))\n",
        "model.add(ZeroPadding2D((0, 2)))\n",
        "model.add(Conv2D(80,(2,3),activation='relu',padding='valid'))\n",
        "model.add(Dropout(dr))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(11,activation='relu'))\n",
        "model.add(Dense(11,activation='softmax'))\n",
        "model.add(Reshape(11))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# model.summary()  This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. \n",
        "model.bulit(input_shape)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo-_6LyBeItF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"##Neural Networks\n",
        "###CNN:VT_CNN2\n",
        "\"\"\"\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Conv1D, Conv2D, Flatten, Dense, Reshape\n",
        "# from keras import optimizers\n",
        "# import keras.models as models\n",
        "\n",
        "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.convolutional import Convolution2D,MaxPooling2D,ZeroPadding2D\n",
        "from keras.optimizers import adam\n",
        "\n",
        "dr = 0.5\n",
        "model = models.Sequential()\n",
        "# model.add(Reshape(1,2,128),input_shape=(2,128))\n",
        "model.add(Reshape((1,2,128), input_shape=(2,128)))\n",
        "model.add(ZeroPadding2D((0,2))) # 为什么加两个括号就不报错了\n",
        "# model.add(Convolution2D(256,1,3),border_mode='valid',activation='relu',name='conv1',init='glorot_uniform') # 后面这些项都算是con里面的吗\n",
        "model.add(Convolution2D(256, 1, 3, border_mode='valid', activation=\"relu\", name=\"conv1\", init='glorot_uniform'))\n",
        "model.add(Dropout(dr))\n",
        "# model.add(ZeroPadding2D(0,2))\n",
        "model.add(Convolution2D(80,2,3,border_mode='valid',activation='relu',name='conv2',init='glorot_uniform'))\n",
        "model.add(Dropout(dr))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu',init='he_normal',name='dense1'))\n",
        "model.add(Dropout(dr))\n",
        "# model.add(Dense(len(classes),init='he_normal',name=dense2''))\n",
        "model.add(Dense( 11, init='he_normal', name=\"dense2\" ))\n",
        "model.add(activation='softmax')\n",
        "# model.add(Reshape([len(classes)]))\n",
        "model.add(Reshape(11))\n",
        "model.compile(loss='categorial_crossentropy',optimize='adam')\n",
        "model.summary()\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=30)\n",
        "mc = ModelCheckpoint('best.hdf5weights.best2.hdf5', monitor='val_acc', mode='max', save_best_only=True, verbose=1)\n",
        "model.fit(xTrain, yTrain_ohe, validation_split=0.05, shuffle=True, batch_size=1000, epochs=10, verbose=1, callbacks=[es, mc])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}